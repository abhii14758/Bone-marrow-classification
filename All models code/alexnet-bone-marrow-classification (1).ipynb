{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if gpu_devices:\n",
    "    tf.config.experimental.set_visible_devices(gpu_devices[1], 'GPU')\n",
    "    print(gpu_devices[1])\n",
    "    print('Success')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-02-07T05:17:20.131115Z",
     "iopub.status.busy": "2024-02-07T05:17:20.130440Z",
     "iopub.status.idle": "2024-02-07T05:17:29.896351Z",
     "shell.execute_reply": "2024-02-07T05:17:29.895507Z",
     "shell.execute_reply.started": "2024-02-07T05:17:20.131082Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras.applications.alexnet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_283974/135717814.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malexnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAlexNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.applications.alexnet'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.alexnet import AlexNet, preprocess_input\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tqdm import tqdm\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-07T05:17:29.898653Z",
     "iopub.status.busy": "2024-02-07T05:17:29.898007Z",
     "iopub.status.idle": "2024-02-07T05:19:11.241510Z",
     "shell.execute_reply": "2024-02-07T05:19:11.240514Z",
     "shell.execute_reply.started": "2024-02-07T05:17:29.898623Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing NGS/3001-4000: 100%|██████████| 1000/1000 [00:00<00:00, 3617.17it/s]\n",
      "Processing NGS/19001-20000: 100%|██████████| 1000/1000 [00:00<00:00, 3508.70it/s]\n",
      "Processing NGS/0001-1000: 100%|██████████| 1000/1000 [00:00<00:00, 3242.29it/s]\n",
      "Processing NGS/4001-5000: 100%|██████████| 1000/1000 [00:00<00:00, 3598.38it/s]\n",
      "Processing NGS/7001-8000: 100%|██████████| 1000/1000 [00:00<00:00, 3346.30it/s]\n",
      "Processing NGS/26001-27000: 100%|██████████| 1000/1000 [00:00<00:00, 3551.64it/s]\n",
      "Processing NGS/13001-14000: 100%|██████████| 1000/1000 [00:00<00:00, 3310.43it/s]\n",
      "Processing NGS/29001-29424: 100%|██████████| 424/424 [00:00<00:00, 95044.89it/s]\n",
      "Processing NGS/12001-13000: 100%|██████████| 1000/1000 [00:00<00:00, 3213.85it/s]\n",
      "Processing NGS/25001-26000: 100%|██████████| 1000/1000 [00:00<00:00, 3444.71it/s]\n",
      "Processing NGS/27001-28000: 100%|██████████| 1000/1000 [00:00<00:00, 3258.77it/s]\n",
      "Processing NGS/28001-29000: 100%|██████████| 1000/1000 [00:00<00:00, 3692.39it/s]\n",
      "Processing NGS/14001-15000: 100%|██████████| 1000/1000 [00:00<00:00, 3693.23it/s]\n",
      "Processing NGS/22001-23000: 100%|██████████| 1000/1000 [00:00<00:00, 3382.91it/s]\n",
      "Processing NGS/9001-10000: 100%|██████████| 1000/1000 [00:00<00:00, 3984.69it/s]\n",
      "Processing NGS/2001-3000: 100%|██████████| 1000/1000 [00:00<00:00, 4082.01it/s]\n",
      "Processing NGS/15001-16000: 100%|██████████| 1000/1000 [00:00<00:00, 4346.95it/s]\n",
      "Processing NGS/18001-19000: 100%|██████████| 1000/1000 [00:00<00:00, 3942.61it/s]\n",
      "Processing NGS/23001-24000: 100%|██████████| 1000/1000 [00:00<00:00, 4019.09it/s]\n",
      "Processing NGS/20001-21000: 100%|██████████| 1000/1000 [00:00<00:00, 4444.06it/s]\n",
      "Processing NGS/10001-11000: 100%|██████████| 1000/1000 [00:00<00:00, 3942.70it/s]\n",
      "Processing NGS/6001-7000: 100%|██████████| 1000/1000 [00:00<00:00, 3874.21it/s]\n",
      "Processing NGS/8001-9000: 100%|██████████| 1000/1000 [00:00<00:00, 4243.96it/s]\n",
      "Processing NGS/16001-17000: 100%|██████████| 1000/1000 [00:00<00:00, 4025.75it/s]\n",
      "Processing NGS/5001-6000: 100%|██████████| 1000/1000 [00:00<00:00, 4561.31it/s]\n",
      "Processing NGS/24001-25000: 100%|██████████| 1000/1000 [00:00<00:00, 4274.32it/s]\n",
      "Processing NGS/17001-18000: 100%|██████████| 1000/1000 [00:00<00:00, 4408.48it/s]\n",
      "Processing NGS/11001-12000: 100%|██████████| 1000/1000 [00:00<00:00, 3980.85it/s]\n",
      "Processing NGS/1001-2000: 100%|██████████| 1000/1000 [00:00<00:00, 3863.38it/s]\n",
      "Processing NGS/21001-22000: 100%|██████████| 1000/1000 [00:00<00:00, 3924.28it/s]\n",
      "Processing MMZ/0001-1000: 100%|██████████| 1000/1000 [00:00<00:00, 3318.13it/s]\n",
      "Processing MMZ/3001-3055: 100%|██████████| 55/55 [00:00<00:00, 59195.98it/s]\n",
      "Processing MMZ/2001-3000: 100%|██████████| 1000/1000 [00:00<00:00, 3867.81it/s]\n",
      "Processing MMZ/1001-2000: 100%|██████████| 1000/1000 [00:00<00:00, 4088.26it/s]\n",
      "Processing MON/3001-4000: 100%|██████████| 1000/1000 [00:00<00:00, 3833.95it/s]\n",
      "Processing MON/0001-1000: 100%|██████████| 1000/1000 [00:00<00:00, 4363.16it/s]\n",
      "Processing MON/2001-3000: 100%|██████████| 1000/1000 [00:00<00:00, 3972.97it/s]\n",
      "Processing MON/4001-4040: 100%|██████████| 40/40 [00:00<00:00, 48799.35it/s]\n",
      "Processing MON/1001-2000: 100%|██████████| 1000/1000 [00:00<00:00, 3831.45it/s]\n",
      "Processing NGB/9001-9968: 100%|██████████| 968/968 [00:00<00:00, 6128.59it/s]\n",
      "Processing NGB/3001-4000: 100%|██████████| 1000/1000 [00:00<00:00, 3719.19it/s]\n",
      "Processing NGB/0001-1000: 100%|██████████| 1000/1000 [00:00<00:00, 4102.65it/s]\n",
      "Processing NGB/4001-5000: 100%|██████████| 1000/1000 [00:00<00:00, 4125.88it/s]\n",
      "Processing NGB/7001-8000: 100%|██████████| 1000/1000 [00:00<00:00, 4311.08it/s]\n",
      "Processing NGB/2001-3000: 100%|██████████| 1000/1000 [00:00<00:00, 4364.09it/s]\n",
      "Processing NGB/6001-7000: 100%|██████████| 1000/1000 [00:00<00:00, 4056.93it/s]\n",
      "Processing NGB/8001-9000: 100%|██████████| 1000/1000 [00:00<00:00, 4003.39it/s]\n",
      "Processing NGB/5001-6000: 100%|██████████| 1000/1000 [00:00<00:00, 5098.45it/s]\n",
      "Processing NGB/1001-2000: 100%|██████████| 1000/1000 [00:00<00:00, 4166.23it/s]\n",
      "Processing ART/3001-4000: 100%|██████████| 1000/1000 [00:00<00:00, 3828.83it/s]\n",
      "Processing ART/0001-1000: 100%|██████████| 1000/1000 [00:00<00:00, 4169.75it/s]\n",
      "Processing ART/4001-5000: 100%|██████████| 1000/1000 [00:00<00:00, 3705.05it/s]\n",
      "Processing ART/7001-8000: 100%|██████████| 1000/1000 [00:00<00:00, 4280.65it/s]\n",
      "Processing ART/19001-19630: 100%|██████████| 630/630 [00:00<00:00, 99724.93it/s]\n",
      "Processing ART/13001-14000: 100%|██████████| 1000/1000 [00:00<00:00, 3733.06it/s]\n",
      "Processing ART/12001-13000: 100%|██████████| 1000/1000 [00:00<00:00, 2815.13it/s]\n",
      "Processing ART/14001-15000: 100%|██████████| 1000/1000 [00:00<00:00, 3581.21it/s]\n",
      "Processing ART/9001-10000: 100%|██████████| 1000/1000 [00:00<00:00, 2970.43it/s]\n",
      "Processing ART/2001-3000: 100%|██████████| 1000/1000 [00:00<00:00, 3425.39it/s]\n",
      "Processing ART/15001-16000: 100%|██████████| 1000/1000 [00:00<00:00, 4124.64it/s]\n",
      "Processing ART/18001-19000: 100%|██████████| 1000/1000 [00:00<00:00, 4244.95it/s]\n",
      "Processing ART/10001-11000: 100%|██████████| 1000/1000 [00:00<00:00, 4014.13it/s]\n",
      "Processing ART/6001-7000: 100%|██████████| 1000/1000 [00:00<00:00, 3803.04it/s]\n",
      "Processing ART/8001-9000: 100%|██████████| 1000/1000 [00:00<00:00, 4278.28it/s]\n",
      "Processing ART/16001-17000: 100%|██████████| 1000/1000 [00:00<00:00, 3961.43it/s]\n",
      "Processing ART/5001-6000: 100%|██████████| 1000/1000 [00:00<00:00, 3203.77it/s]\n",
      "Processing ART/17001-18000: 100%|██████████| 1000/1000 [00:00<00:00, 3367.26it/s]\n",
      "Processing ART/11001-12000: 100%|██████████| 1000/1000 [00:00<00:00, 4070.97it/s]\n",
      "Processing ART/1001-2000: 100%|██████████| 1000/1000 [00:00<00:00, 3988.00it/s]\n",
      "Processing PLM/3001-4000: 100%|██████████| 1000/1000 [00:00<00:00, 3999.11it/s]\n",
      "Processing PLM/0001-1000: 100%|██████████| 1000/1000 [00:00<00:00, 4322.62it/s]\n",
      "Processing PLM/4001-5000: 100%|██████████| 1000/1000 [00:00<00:00, 4127.25it/s]\n",
      "Processing PLM/7001-7629: 100%|██████████| 629/629 [00:00<00:00, 94404.11it/s]\n",
      "Processing PLM/2001-3000: 100%|██████████| 1000/1000 [00:00<00:00, 4025.78it/s]\n",
      "Processing PLM/6001-7000: 100%|██████████| 1000/1000 [00:00<00:00, 3995.98it/s]\n",
      "Processing PLM/5001-6000: 100%|██████████| 1000/1000 [00:00<00:00, 4239.98it/s]\n",
      "Processing PLM/1001-2000: 100%|██████████| 1000/1000 [00:00<00:00, 3967.29it/s]\n",
      "Processing NIF/0001-1000: 100%|██████████| 1000/1000 [00:00<00:00, 4068.32it/s]\n",
      "Processing NIF/2001-3000: 100%|██████████| 1000/1000 [00:00<00:00, 4289.77it/s]\n",
      "Processing NIF/3001-3538: 100%|██████████| 538/538 [00:00<00:00, 95676.72it/s]\n",
      "Processing NIF/1001-2000: 100%|██████████| 1000/1000 [00:00<00:00, 4116.07it/s]\n",
      "Processing MYB/3001-4000: 100%|██████████| 1000/1000 [00:00<00:00, 3810.80it/s]\n",
      "Processing MYB/0001-1000: 100%|██████████| 1000/1000 [00:00<00:00, 3772.87it/s]\n",
      "Processing MYB/4001-5000: 100%|██████████| 1000/1000 [00:00<00:00, 3473.07it/s]\n",
      "Processing MYB/2001-3000: 100%|██████████| 1000/1000 [00:00<00:00, 3927.75it/s]\n",
      "Processing MYB/5001-6000: 100%|██████████| 1000/1000 [00:00<00:00, 3812.33it/s]\n",
      "Processing MYB/1001-2000: 100%|██████████| 1000/1000 [00:00<00:00, 3384.54it/s]\n",
      "Processing MYB/6001-6557: 100%|██████████| 557/557 [00:00<00:00, 87257.31it/s]\n",
      "Processing EBO/3001-4000: 100%|██████████| 1000/1000 [00:00<00:00, 4273.00it/s]\n",
      "Processing EBO/19001-20000: 100%|██████████| 1000/1000 [00:00<00:00, 3605.03it/s]\n",
      "Processing EBO/0001-1000: 100%|██████████| 1000/1000 [00:00<00:00, 3738.42it/s]\n",
      "Processing EBO/4001-5000: 100%|██████████| 1000/1000 [00:00<00:00, 3943.49it/s]\n",
      "Processing EBO/7001-8000: 100%|██████████| 1000/1000 [00:00<00:00, 3920.36it/s]\n",
      "Processing EBO/26001-27000: 100%|██████████| 1000/1000 [00:00<00:00, 4109.59it/s]\n",
      "Processing EBO/13001-14000: 100%|██████████| 1000/1000 [00:00<00:00, 3639.53it/s]\n",
      "Processing EBO/12001-13000: 100%|██████████| 1000/1000 [00:00<00:00, 3858.19it/s]\n",
      "Processing EBO/25001-26000: 100%|██████████| 1000/1000 [00:00<00:00, 3541.82it/s]\n",
      "Processing EBO/27001-27395: 100%|██████████| 395/395 [00:00<00:00, 86154.45it/s]\n",
      "Processing EBO/14001-15000: 100%|██████████| 1000/1000 [00:00<00:00, 3972.63it/s]\n",
      "Processing EBO/22001-23000: 100%|██████████| 1000/1000 [00:00<00:00, 3269.74it/s]\n",
      "Processing EBO/9001-10000: 100%|██████████| 1000/1000 [00:00<00:00, 2758.21it/s]\n",
      "Processing EBO/2001-3000: 100%|██████████| 1000/1000 [00:00<00:00, 2689.28it/s]\n",
      "Processing EBO/15001-16000: 100%|██████████| 1000/1000 [00:00<00:00, 3393.89it/s]\n",
      "Processing EBO/18001-19000: 100%|██████████| 1000/1000 [00:00<00:00, 3854.16it/s]\n",
      "Processing EBO/23001-24000: 100%|██████████| 1000/1000 [00:00<00:00, 3607.49it/s]\n",
      "Processing EBO/20001-21000: 100%|██████████| 1000/1000 [00:00<00:00, 2852.81it/s]\n",
      "Processing EBO/10001-11000: 100%|██████████| 1000/1000 [00:00<00:00, 3657.81it/s]\n",
      "Processing EBO/6001-7000: 100%|██████████| 1000/1000 [00:00<00:00, 3217.12it/s]\n",
      "Processing EBO/8001-9000: 100%|██████████| 1000/1000 [00:00<00:00, 3748.31it/s]\n",
      "Processing EBO/16001-17000: 100%|██████████| 1000/1000 [00:00<00:00, 3281.16it/s]\n",
      "Processing EBO/5001-6000: 100%|██████████| 1000/1000 [00:00<00:00, 3358.56it/s]\n",
      "Processing EBO/24001-25000: 100%|██████████| 1000/1000 [00:00<00:00, 3876.96it/s]\n",
      "Processing EBO/17001-18000: 100%|██████████| 1000/1000 [00:00<00:00, 3573.19it/s]\n",
      "Processing EBO/11001-12000: 100%|██████████| 1000/1000 [00:00<00:00, 3296.93it/s]\n",
      "Processing EBO/1001-2000: 100%|██████████| 1000/1000 [00:00<00:00, 3014.96it/s]\n",
      "Processing EBO/21001-22000: 100%|██████████| 1000/1000 [00:00<00:00, 3589.85it/s]\n",
      "Processing LYT/26001-26242: 100%|██████████| 242/242 [00:00<00:00, 47891.93it/s]\n",
      "Processing LYT/3001-4000: 100%|██████████| 1000/1000 [00:00<00:00, 3792.86it/s]\n",
      "Processing LYT/19001-20000: 100%|██████████| 1000/1000 [00:00<00:00, 4181.39it/s]\n",
      "Processing LYT/0001-1000: 100%|██████████| 1000/1000 [00:00<00:00, 4765.86it/s]\n",
      "Processing LYT/4001-5000: 100%|██████████| 1000/1000 [00:00<00:00, 4105.01it/s]\n",
      "Processing LYT/7001-8000: 100%|██████████| 1000/1000 [00:00<00:00, 3783.82it/s]\n",
      "Processing LYT/13001-14000: 100%|██████████| 1000/1000 [00:00<00:00, 4692.26it/s]\n",
      "Processing LYT/12001-13000: 100%|██████████| 1000/1000 [00:00<00:00, 4130.51it/s]\n",
      "Processing LYT/25001-26000: 100%|██████████| 1000/1000 [00:00<00:00, 4355.80it/s]\n",
      "Processing LYT/14001-15000: 100%|██████████| 1000/1000 [00:00<00:00, 4826.59it/s]\n",
      "Processing LYT/22001-23000: 100%|██████████| 1000/1000 [00:00<00:00, 3784.43it/s]\n",
      "Processing LYT/9001-10000: 100%|██████████| 1000/1000 [00:00<00:00, 3558.54it/s]\n",
      "Processing LYT/2001-3000: 100%|██████████| 1000/1000 [00:00<00:00, 4155.60it/s]\n",
      "Processing LYT/15001-16000: 100%|██████████| 1000/1000 [00:00<00:00, 3857.10it/s]\n",
      "Processing LYT/18001-19000: 100%|██████████| 1000/1000 [00:00<00:00, 3876.34it/s]\n",
      "Processing LYT/23001-24000: 100%|██████████| 1000/1000 [00:00<00:00, 3972.03it/s]\n",
      "Processing LYT/20001-21000: 100%|██████████| 1000/1000 [00:00<00:00, 4058.41it/s]\n",
      "Processing LYT/10001-11000: 100%|██████████| 1000/1000 [00:00<00:00, 4119.02it/s]\n",
      "Processing LYT/6001-7000: 100%|██████████| 1000/1000 [00:00<00:00, 4921.11it/s]\n",
      "Processing LYT/8001-9000: 100%|██████████| 1000/1000 [00:00<00:00, 3372.13it/s]\n",
      "Processing LYT/16001-17000: 100%|██████████| 1000/1000 [00:00<00:00, 4126.44it/s]\n",
      "Processing LYT/5001-6000: 100%|██████████| 1000/1000 [00:00<00:00, 3771.94it/s]\n",
      "Processing LYT/24001-25000: 100%|██████████| 1000/1000 [00:00<00:00, 4637.71it/s]\n",
      "Processing LYT/17001-18000: 100%|██████████| 1000/1000 [00:00<00:00, 4336.25it/s]\n",
      "Processing LYT/11001-12000: 100%|██████████| 1000/1000 [00:00<00:00, 3963.23it/s]\n",
      "Processing LYT/1001-2000: 100%|██████████| 1000/1000 [00:00<00:00, 3791.33it/s]\n",
      "Processing LYT/21001-22000: 100%|██████████| 1000/1000 [00:00<00:00, 3492.22it/s]\n",
      "Processing BLA/3001-4000: 100%|██████████| 1000/1000 [00:00<00:00, 4830.40it/s]\n",
      "Processing BLA/0001-1000: 100%|██████████| 1000/1000 [00:00<00:00, 3518.70it/s]\n",
      "Processing BLA/4001-5000: 100%|██████████| 1000/1000 [00:00<00:00, 4048.77it/s]\n",
      "Processing BLA/7001-8000: 100%|██████████| 1000/1000 [00:00<00:00, 3958.26it/s]\n",
      "Processing BLA/9001-10000: 100%|██████████| 1000/1000 [00:00<00:00, 4023.09it/s]\n",
      "Processing BLA/2001-3000: 100%|██████████| 1000/1000 [00:00<00:00, 4112.05it/s]\n",
      "Processing BLA/10001-11000: 100%|██████████| 1000/1000 [00:00<00:00, 4038.48it/s]\n",
      "Processing BLA/6001-7000: 100%|██████████| 1000/1000 [00:00<00:00, 4458.29it/s]\n",
      "Processing BLA/8001-9000: 100%|██████████| 1000/1000 [00:00<00:00, 3758.13it/s]\n",
      "Processing BLA/11001-11973: 100%|██████████| 973/973 [00:00<00:00, 6040.57it/s]\n",
      "Processing BLA/5001-6000: 100%|██████████| 1000/1000 [00:00<00:00, 3864.71it/s]\n",
      "Processing BLA/1001-2000: 100%|██████████| 1000/1000 [00:00<00:00, 3956.17it/s]\n",
      "Processing EOS/3001-4000: 100%|██████████| 1000/1000 [00:00<00:00, 3836.82it/s]\n",
      "Processing EOS/0001-1000: 100%|██████████| 1000/1000 [00:00<00:00, 3579.50it/s]\n",
      "Processing EOS/4001-5000: 100%|██████████| 1000/1000 [00:00<00:00, 3500.05it/s]\n",
      "Processing EOS/2001-3000: 100%|██████████| 1000/1000 [00:00<00:00, 3717.58it/s]\n",
      "Processing EOS/5001-5883: 100%|██████████| 883/883 [00:00<00:00, 91308.66it/s]\n",
      "Processing EOS/1001-2000: 100%|██████████| 1000/1000 [00:00<00:00, 4148.51it/s]\n",
      "Processing PMO/11001-11994: 100%|██████████| 994/994 [00:00<00:00, 3959.80it/s]\n",
      "Processing PMO/3001-4000: 100%|██████████| 1000/1000 [00:00<00:00, 4115.40it/s]\n",
      "Processing PMO/0001-1000: 100%|██████████| 1000/1000 [00:00<00:00, 4048.18it/s]\n",
      "Processing PMO/4001-5000: 100%|██████████| 1000/1000 [00:00<00:00, 3994.05it/s]\n",
      "Processing PMO/7001-8000: 100%|██████████| 1000/1000 [00:00<00:00, 4063.02it/s]\n",
      "Processing PMO/9001-10000: 100%|██████████| 1000/1000 [00:00<00:00, 4347.27it/s]\n",
      "Processing PMO/2001-3000: 100%|██████████| 1000/1000 [00:00<00:00, 4106.04it/s]\n",
      "Processing PMO/10001-11000: 100%|██████████| 1000/1000 [00:00<00:00, 3410.04it/s]\n",
      "Processing PMO/6001-7000: 100%|██████████| 1000/1000 [00:00<00:00, 4256.63it/s]\n",
      "Processing PMO/8001-9000: 100%|██████████| 1000/1000 [00:00<00:00, 3480.60it/s]\n",
      "Processing PMO/5001-6000: 100%|██████████| 1000/1000 [00:00<00:00, 4292.51it/s]\n",
      "Processing PMO/1001-2000: 100%|██████████| 1000/1000 [00:00<00:00, 3673.09it/s]\n",
      "Processing PEB/0001-1000: 100%|██████████| 1000/1000 [00:00<00:00, 4179.55it/s]\n",
      "Processing PEB/2001-2740: 100%|██████████| 740/740 [00:00<00:00, 99547.29it/s]\n",
      "Processing PEB/1001-2000: 100%|██████████| 1000/1000 [00:00<00:00, 3971.28it/s]\n"
     ]
    }
   ],
   "source": [
    "# Path to your dataset\n",
    "data_dir = '../Data/bone_marrow_cell_dataset'\n",
    "\n",
    "# List to store image paths and labels\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "# Loop through class directories\n",
    "\n",
    "for class_name in os.listdir(data_dir):\n",
    "    class_dir = os.path.join(data_dir, class_name)\n",
    "    \n",
    "    if os.path.isdir(class_dir):\n",
    "        for sub_dir_name in os.listdir(class_dir):\n",
    "            sub_dir_path = os.path.join(class_dir, sub_dir_name)\n",
    "            \n",
    "            if os.path.isdir(sub_dir_path):\n",
    "                for img_name in tqdm(os.listdir(sub_dir_path), desc=f\"Processing {class_name}/{sub_dir_name}\"):\n",
    "                    img_path = os.path.join(sub_dir_path, img_name)\n",
    "                    if os.path.isfile(img_path):\n",
    "                        image_paths.append(img_path)\n",
    "                        labels.append(class_name)\n",
    "            else:\n",
    "                img_path = os.path.join(class_dir, sub_dir_name)\n",
    "                if os.path.isfile(img_path):\n",
    "                    image_paths.append(img_path)\n",
    "                    labels.append(class_name)\n",
    "    else:\n",
    "        img_path = class_dir  # For classes without subdirectories\n",
    "        if os.path.isfile(img_path):\n",
    "            image_paths.append(img_path)\n",
    "            labels.append(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-07T05:19:11.243408Z",
     "iopub.status.busy": "2024-02-07T05:19:11.243091Z",
     "iopub.status.idle": "2024-02-07T05:19:11.389168Z",
     "shell.execute_reply": "2024-02-07T05:19:11.388235Z",
     "shell.execute_reply.started": "2024-02-07T05:19:11.243377Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes: {'OTH', 'ART', 'NGS', 'PEB', 'ABE', 'BLA', 'MYB', 'KSC', 'BAS', 'PMO', 'HAC', 'MON', 'NIF', 'MMZ', 'EOS', 'PLM', 'LYT', 'EBO', 'FGC', 'NGB', 'LYI'}\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into train, test, and validation sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(image_paths, labels, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Now X_train, y_train, X_val, y_val, X_test, y_test are the organized data for training, validation, and testing\n",
    "# Combine all labels from train, validation, and test sets\n",
    "combined_labels = y_train + y_val + y_test\n",
    "\n",
    "# Print all unique classes\n",
    "unique_classes = set(combined_labels)\n",
    "print(\"Unique classes:\", unique_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-07T05:19:14.126371Z",
     "iopub.status.busy": "2024-02-07T05:19:14.125549Z",
     "iopub.status.idle": "2024-02-07T05:19:14.244497Z",
     "shell.execute_reply": "2024-02-07T05:19:14.243578Z",
     "shell.execute_reply.started": "2024-02-07T05:19:14.126339Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Convert string labels to numerical labels using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_val_encoded = label_encoder.transform(y_val)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Calculate the number of classes directly from the labels\n",
    "num_classes = len(set(combined_labels))\n",
    "\n",
    "# Convert numerical labels to one-hot encoded vectors\n",
    "y_train_onehot = to_categorical(y_train_encoded, num_classes)\n",
    "y_val_onehot = to_categorical(y_val_encoded, num_classes)\n",
    "y_test_onehot = to_categorical(y_test_encoded, num_classes)\n",
    "\n",
    "num_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-07T05:19:15.890673Z",
     "iopub.status.busy": "2024-02-07T05:19:15.889857Z",
     "iopub.status.idle": "2024-02-07T05:19:20.968839Z",
     "shell.execute_reply": "2024-02-07T05:19:20.968039Z",
     "shell.execute_reply.started": "2024-02-07T05:19:15.890641Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Change input shape to match AlexNet's input shape\n",
    "base_model = AlexNet(weights='imagenet', include_top=False, input_shape=(227, 227, 3))\n",
    "\n",
    "# Add custom layers on top of the base model\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-07T05:19:20.970664Z",
     "iopub.status.busy": "2024-02-07T05:19:20.970360Z",
     "iopub.status.idle": "2024-02-07T05:19:20.988049Z",
     "shell.execute_reply": "2024-02-07T05:19:20.987236Z",
     "shell.execute_reply.started": "2024-02-07T05:19:20.970638Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-07T05:19:22.687594Z",
     "iopub.status.busy": "2024-02-07T05:19:22.687207Z",
     "iopub.status.idle": "2024-02-07T05:19:22.709293Z",
     "shell.execute_reply": "2024-02-07T05:19:22.708467Z",
     "shell.execute_reply.started": "2024-02-07T05:19:22.687563Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               6422784   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 21)                5397      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,142,869\n",
      "Trainable params: 21,142,869\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-07T05:19:24.114437Z",
     "iopub.status.busy": "2024-02-07T05:19:24.113791Z",
     "iopub.status.idle": "2024-02-07T05:19:24.122127Z",
     "shell.execute_reply": "2024-02-07T05:19:24.121240Z",
     "shell.execute_reply.started": "2024-02-07T05:19:24.114406Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocess images using ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,  \n",
    "    rescale=1. / 255\n",
    ")\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Define a custom generator to load and preprocess images on-the-fly\n",
    "def custom_generator(image_paths, labels, batch_size):\n",
    "    num_samples = len(image_paths)\n",
    "    while True:\n",
    "        indices = np.random.choice(num_samples, size=batch_size, replace=False)\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "        for idx in indices:\n",
    "            img_path = image_paths[idx]\n",
    "            label = labels[idx]\n",
    "            try:\n",
    "                img = load_img(img_path, target_size=(250, 250))  # Resize images to VGG-16 input size\n",
    "                img_array = img_to_array(img)\n",
    "                batch_images.append(img_array)\n",
    "                batch_labels.append(label)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {img_path}: {e}\")\n",
    "        yield np.array(batch_images), to_categorical(label_encoder.transform(batch_labels), num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filepath = 'AlexNet_weights.hdf5'\n",
    "callbacks_list = [EarlyStopping(monitor='val_accuracy', patience=10, verbose=1),\n",
    "                  ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max'),\n",
    "                  ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=5, verbose=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom generators for training, validation, and test sets\n",
    "train_generator = custom_generator(X_train, y_train, batch_size)\n",
    "val_generator = custom_generator(X_val, y_val, batch_size)\n",
    "test_generator = custom_generator(X_test, y_test, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-07T05:19:28.633443Z",
     "iopub.status.busy": "2024-02-07T05:19:28.632805Z",
     "iopub.status.idle": "2024-02-07T05:20:22.017129Z",
     "shell.execute_reply": "2024-02-07T05:20:22.015837Z",
     "shell.execute_reply.started": "2024-02-07T05:19:28.633408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "  56/3748 [..............................] - ETA: 29:50 - loss: 7.1592 - accuracy: 0.1406"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "\n",
    "# Train the model using the custom generator\n",
    "model.fit(\n",
    "    custom_generator(X_train, y_train, batch_size),\n",
    "    steps_per_epoch=len(X_train) // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=custom_generator(X_val, y_val, batch_size),\n",
    "    validation_steps=len(X_val) // batch_size,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('AlexNet_Model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final = load_model('AlexNet_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set using the custom generator\n",
    "test_loss, test_accuracy = model_final.evaluate(\n",
    "    test_generator,\n",
    "    steps=len(X_test) // batch_size,\n",
    "    verbose=1,\n",
    ")\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Determine the size of the test dataset\n",
    "test_size = len(X_test)\n",
    "\n",
    "print(\"Total number of samples in the test dataset:\", test_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from math import ceil\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Determine the size of the test dataset\n",
    "test_size = len(X_test)\n",
    "\n",
    "# Calculate the number of steps based on batch size\n",
    "batch_size = 32  # Adjust according to your generator's batch size\n",
    "test_steps = ceil(test_size / batch_size)\n",
    "\n",
    "# Initialize empty lists to store true and predicted labels\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# Iterate through the test generator to obtain predictions batch-wise\n",
    "for i in range(test_steps):\n",
    "    x_batch, y_batch = next(test_generator)\n",
    "    y_true.extend(np.argmax(y_batch, axis=1))\n",
    "    y_pred.extend(np.argmax(model_final.predict(x_batch), axis=1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Get the list of all possible classes\n",
    "all_classes = sorted(set(y_true + y_pred + y_train_encoded.tolist()))\n",
    "\n",
    "# Calculate confusion matrix with all classes\n",
    "conf_matrix = confusion_matrix(y_true, y_pred, labels=all_classes)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(11.7, 8.27), dpi=200)\n",
    "plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "\n",
    "tick_marks = np.arange(len(all_classes))\n",
    "\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        plt.text(j, i, conf_matrix[i, j],\n",
    "                 ha=\"center\", va=\"center\",\n",
    "                 color=\"white\" if conf_matrix[i, j] > conf_matrix.max() / 2 else \"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.xticks(tick_marks, unique_classes, rotation=45)\n",
    "plt.yticks(tick_marks, unique_classes)\n",
    "plt.savefig('AlexNet.png')\n",
    "plt.show()\n",
    "\n",
    "# Calculate classification report\n",
    "class_report = classification_report(y_true, y_pred,target_names=unique_classes)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1855740,
     "sourceId": 3082954,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
